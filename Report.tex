\documentclass[12pt,letterpaper, twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{dirtytalk}
\usepackage[export]{adjustbox}

\title{COVID-19 Open Data : Map-Reduction and Visualisation}
\author{Tafara Freddie Hove \\
        \small u18278150 \\
}
\date{}

% K
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1 
}

\begin{document}
\maketitle
\begin{abstract}


Big data  causes many challenges to conventional data analysis and mining  techniques due to its characteristics like volume, velocity and variety. Hence, there is need for more advanced technologies that can process and analyse Big data  effectively and efficiently. This report discusses the COVID-19 Data, which Big Data and how  to use Apache Spark on such datasets. Applying analytical task to big data can help extract valuable information that can be used to curb the spread of COVID-19  pandemic and safe more lives. Data analysis and visualisation will be done on the selected attributes using Spark Mapreduce tools



\end{abstract}\hspace{10pt}
\keywords{COVID-19, Apache Spark, Mapreduce, Visualisation}

\section{INTRODUCTION}
Apache Spark is a distributed computing  technology that can processes large datasets. A Mapreducing model is required to analyze COVID-19 data to give insight about the patterns and trends of active, confirmed, recovered and deceased cases in the world and South Africa in particular. Mapreduce is very efficient for batch processing and it can be implemented on Apache Spark which is very efficient for iterative in-memory computing and this combination simplifies supports distributed and parallel applications that handle giant quantity information. Mapreduce is a software framework  that can process massive datasets in a distributed environment over several devices \cite{}. 

 Mapreduce involves the mapping the data in a collection of (key, value) pairs and reducing all the pairs using the same key. Map function can do grouping, filtering and sorting of data. On the other hand, reduce function aggregates and summarizes the data results generated by the map function. In the project we analyze and visualize the COViD-19 Open dataset, an open data source  which can help about a better understanding of health status of the world at large. Processing and analysing Big Data on a local machine using traditional techniques such as excel posses a big challenge.
 
 In order to  have a perspective of the world health issues related to COVID-19 there are question that are going to be dicussed and answered during the data analysis and visualisation.
 
 This paper is giving a comprehensive examination of of the CIVID-19 Open dataset using Apache Spark processing tools and disscuses the processeses, approaches,results and visualize of the executed operations. The paper's layout as follows ; Section 2 --------

\section{DATASET}
 In this  section, the detailed overview of the COVID-19 open dataset is presented. The dataset reveals main aspects of COVID-19. The section explains the dataset, highlighting some key interesting characterstics and discuss some attributes that possess some interesting aspects  within the dataset.

\subsection{Dataset Overview}

 As discussed in PART 1 of the this project;  COVID-19 Open Data is a huge dataset that consists of country-level datasets of daily time-series data about COVID-19 worldwide \cite{covid-19}.The repository contains datasets of more than 50 countries around the world for the timespan February 2020 to date. The data is disaggregated  by country or by regions. The datasets reveal the impact of the virus and how different countries are responding to the pandemic.  It contains the latest available public data on COVID-19 including a daily situation update, the epidemiological curve and the global geographical distribution \cite{covid-19}. The COVID-19 Open Data is available at https://github.com/GoogleCloudPlatform/covid-19-open-data. This is dataset is made up of live data files in the Google Cloud directory.

The COVID-19 Open Data is collected from multiple sources such as Wikidata, DataCommons, WorldBank, University of Oxford and Google. The data is sourced from different countries through the initiative of the World Health Organisation's Epidemic Intelligence on daily basis. The data reports are based on the number of COVID-19  confirmed, recovered, tested and deaths cases, from health authorities worldwide etc. Hence the dataset is a resource of multiple types of data outcomes, static co-variate data, dynamic co-variate data and dynamic intervention state data\cite{covid-19}.The data is stored in separate CSV and JSON files which are published in Google Cloud Storage. The collection of such huge quantities of files constitutes 1.01GB of data.  The merged datasets' size has  more than 6112480 observations and 45 attributes.  The attributes types are strings and numeric values. The dataset that is stored on BiQuery Puplic dataset program.

\subsection{Features Selection}
Feature selection is a process where a subset of attributes or variables of a dataset are selected for further processing to address the task at hand. The attributes which are  not to have interesting information are removed. New  attributes can also be created and added to the data frame. Hence the  attributes  of interest were selected from the dataset  to do some data analysis using Map-reduce.  Such data analysis using the selected attributes will help to calculate and determine needed measures to curb the spread of the pandemic and its devastating consequences. They can also reveal the relationship between the spread of the virus in a country and how people's lives and livelihoods are being affected in a country.

Below is a list of selected variables and reason their inclusion in the data analysis:

\begin{itemize}
    \item date: This is the day a COVID-19 case was recorded or confirmed. It helps to monitor the trends (increases/decrease in number of cases) of the pandemic.
    For each date, the cumulative number of confirmed cases and deaths as reported that day in that county or state are shown. All cases and deaths are counted on the date they are first announced.
    
    \item country name: The column reveals names of countries and which countries are making progress against the pandemic. It shows what measures implemented by a country in response to the pandemic.
    
    \item region:  The column illustrates states/provinces of different countries and how each geographic area responds to the pandemic.
    
    \item cumulative confirmed: This column shows the total number of recorded positive cases from the day the first case was recorded. 
      
    \item cumulative confirmed deceased /new:  Is the total deaths from conoravirus recorded. Help to check if the number of deaths are increasing or not , compared to other countries. This shows if the country is able to contain the pandemic or not? Is the death toll continues to rise quickly daily or weekly?
    
    \item cumulative recovered: The number of number of people infected and recovered from coronavirus
      
     \item cumulative test:  It shows how much testing for coronavirus do countries conduct, when it started how does it compared with other countries? if the number of confirmed cases is lower than the actual cases , then it means that there is limited testing in that country.
      
    \item new confirmed cases:  It reveals how the country performs test relative to the size of the outbreak
    
\end{itemize}


\subsection{Investigative Questions}

\begin{enumerate}
    \item Which  ten countries have the highest number of commutative confirmed, cumulative deceased and recoveries cases?
    \item  Which countries have the highest active cases ?
    \item How does the number of confirmed cases correspond to hospitalizations and deaths?
    \item how does economic actives, people mobility and recreation where affected by the pandemic?
    \item Which provinces in South Africa has the  confirmed cases highest cases ?
    \item Is the spread of COVID-19 associated with weather condition (temperature)?
    \item has the number of infections changed over time in most countries?
\end{enumerate}

in order to address the questions above  some  data manipulation, processing and analysis were data on the define environment as discussed in the next section.

\section{METHODOLOGY}
Apache Spark open source platform was used for processing data on the Google Cloud Platform. Spark is fast, scalable, fault tolerant and distributed. Hence it is referred to as the general engine for processing large scale data  \cite{Chouksey and Chauhan, 2017}. Hence Spark was implemented for mapreducing. Mapreduce framework efficiently distributes the job over a number of commodity hardware and calculate the result in parallel. Spark can efficiently analyzes large data sets since it relies on in-memory storage for computing. Its main core data structure is RDD which is a dataset distributed across the RAM  of each computer in a cluster. The calculation is in Spark are executed through pipelining using transformation (map, reduceByKey) and action (take, reduce, collect) operations. To ensure effective COVID-19 data analytics using Spark Mapreduce the number of operations were implemented.

\subsection{ Google Cloud Dataproc Cluster Setup}
Firstly, the project was created on Google Cloud platform console. The cloud storage bucket to be used on the Dataproc cluster was created to store data files from BigQuery . The we installed and ran a Jupypter notebook on a Dataproc cluster. The Python 3 kernel was used to configure the SparkSession in the notebook. 

The Dataproc hadoop cluster with Apache Spark were setup on the three nodes with one master (namenode) and two worker nodes(datanodes). The cluster was created in a defined region and zone. Each node had 2V CPU3.75GB n1-standard core, and 32GB disk size storage capacity. Then the latest version of hadoop 2.9 and spark 2.4 was used to setup the cluster. In a dataproc hadoop cluster, the jupyter notebook for python was was also accessed for the processing of big data.  In the dataproc cluster notebook the spark-bigquery-connector and BigQuery Storage API were used to  load data into the Spark Cluster. Then the Spark data from can be created by reading in data from the public BigQuery dataset. 

\subsection{ Exploratory Data Analysis}
Data exploration analysis is the very first and critical step in data analysis process. It involves the exploring of the data to identity the data patterns, trends, variable characteristics and other interesting points. it helps to understand the key concepts and issues of the data so as to get a better informed representation of the entire dataset. Through data exploration on notebooks the dimensions of the dataset and the variable types were identified. Hence the data set was cut into a manageable size, focusing on analyzing the most relevant attribute discussed in section II. 

\subsection{Data preparation}
 This a data extraction process which involves data preparation activities such cleaning, transforming and rearranging of data. The dataset had missing data and duplicate data. The duplicate rows were removed, and missing values were replaced. Some features were selected and other were drop for data analysis. Hence the data was rearranged in various ways to ensure  manipulation of datasets. 


\subsection{Spark SQL}
Spark is an efficient and fast engine used to process and analyze large-scale data. It is an in-memory computation hence it was chosen over Hadoop Map-Reduce which read  and write to a disk which makes slow. Spark SQl and Spark RDDs are the key technologies for data analysis in Spark. Moreover, in this project Spark SQL was used for querying  and analyzing the dataset. SQL can easily  query DataFrames and familiar queries can also be executed on top of park for data analysis.

\section{ANALYSIS AND RESULTS}

This section presents the results of analyzed attributes extracted from the dataset. The purpose is to reveal the project findings  in relation to the insights that were mined from the data. As discussed in the last section, Spark SQL was used to query the dataset to answer the  investigative questions highlighted in the previous section. The graphs and maps will clearly illustrate the findings and solutions to the  questions in the next section.  

\begin{enumerate}
    \item Cumulative confirmed cases vs Cumulative confirmed deaths 
    The result of the project shows that  from top 20 countries with high cumulative conformed cases, they have also very high deaths. For instance United States of America has a total of 9126351 confirmed cases and 230556, followed by india with 8184082 confirmed cases and 122111 deaths. In Africa, the most affected country is South Africa with 725452 cumulative confirmed cases and 19276 death cases. Seemingly this reveals that as more people get infected with COVID-19 virus a sizeable numbered of people is expected to die. In addition the findings also showed that more people were hospitalized.On the other hand the number of confirmed cases depend on the number of test done in the country. The countries all the countries have very high number of people who tested for COVID-19.  Hence there is a high correlation between cumulative confirmed and  cumulative deceased cases. 
    
    \item Active cases
    The active case finding is another key for the control and prevention communicable diseases. The active cases are were calculated by subtracting the total deceased and total recovered from the total confirmed cases. The active cases are fluctuating day by day and country by country.  But  there statistics revealed that country with high active cases have also high deaths and hospitalisations like USA, UK, Spain and South Africa.
    
    \item Cases in South Africa
    South Africa is the country in Africa with the highest number of  COVID-19 infections. South Africa COVID-19 data was extracted from the main dataset. The statistics revealed that more cases were concentrated in Gauteng with 228756 confirmed cases and Western Cape recorded 117 326.  The percentage ratio of the cases are as follows ----. In addtion high  number of hospitalisations and death cases are also confirmed in these provinces. 
    
    
    \item Checking trends on the number of new infections per pay in SAin the past 100 days
    The aim is to analyze the patterns in the last 100 days  to check wther the infections are increasing or decresing in South Africa.
    
    
\end{enumerate}

\section{VISUALISATION}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth, height=5cm]{linegraph.png}
\caption{Caption}
\label{fig:figure2}
\end{figure}

\end{document}















